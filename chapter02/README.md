## Multi-arm Bandits

*Chapter 2*

#### Epsilon Greedy Process

This is a reproduction of Figure 2.1 from the book:

![Figure 2.1 - Average Reward](images/Figure-2.1-AverageReward.png)
![Figure 2.1 - Optimal Action](images/Figure-2.1-OptimalAction.png)

This is a reproduction of Figure 2.2 from the book:

![Figure 2.2 - Average Reward](images/Figure-2.2-AverageReward.png)
![Figure 2.2 - Optimal Action](images/Figure-2.2-OptimalAction.png)

#### Upper Confidence Bound

This is a reproduction of Figure 2.3 from the book:

![Figure 2.3 - Average Reward](images/Figure-2.3-AverageReward.png)
![Figure 2.3 - Optimal Action](images/Figure-2.3-OptimalAction.png)

#### Gradient Ascent Bandit

This is a reproduction of Figure 2.4 from the book:

![Figure 2.4 - Average Reward](images/Figure-2.4-AverageReward.png)
![Figure 2.4 - Optimal Action](images/Figure-2.4-OptimalAction.png)
