## Multi-arm Bandits

*Chapter 2*

#### Epsilon Greedy Process

This is a reproduction of Figure 2.1 from the book:

![Figure 2.1 - Epsilon Greedy Process - Average Reward](images/Figure-2.1-EpsilonGreedyProcess-AverageReward.png)
![Figure 2.1 - Epsilon Greedy Process - Optimal Action](images/Figure-2.1-EpsilonGreedyProcess-OptimalAction.png)

This is a reproduction of Figure 2.2 from the book:

![Figure 2.2 - Epsilon Greedy Process - Average Reward](images/Figure-2.2-EpsilonGreedyProcess-AverageReward.png)
![Figure 2.2 - Epsilon Greedy Process - Optimal Action](images/Figure-2.2-EpsilonGreedyProcess-OptimalAction.png)

#### Upper Confidence Bound

This is a reproduction of Figure 2.3 from the book:

![Figure 2.3 - Upper Confidence Bound - Average Reward](images/Figure-2.3-UpperConfidenceBound-AverageReward.png)
![Figure 2.3 - Upper Confidence Bound - Optimal Action](images/Figure-2.3-UpperConfidenceBound-OptimalAction.png)

#### Gradient Ascent Bandit

This is a reproduction of Figure 2.4 from the book:

![Figure 2.4 - Gradient Ascent Bandit - Average Reward](images/Figure-2.4-GradientAscentBandit-AverageReward.png)
![Figure 2.4 - Gradient Ascent Bandit - Optimal Action](images/Figure-2.4-GradientAscentBandit-OptimalAction.png)
